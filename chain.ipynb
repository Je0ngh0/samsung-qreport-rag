{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d350fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/how_to/custom_embeddings/\n",
    "\n",
    "from typing import List, Iterable, Union\n",
    "\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel, BitsAndBytesConfig\n",
    "\n",
    "def _last_token_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "class MyEmbeddings(Embeddings):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = \"Qwen/Qwen3-Embedding-8B\",\n",
    "        *,\n",
    "        max_length: int = 8192,\n",
    "        device = None\n",
    "    ):\n",
    "        self.model_name = model\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self._tokenizer = tokenizer = AutoTokenizer.from_pretrained(self.model_name, padding_side='left')\n",
    "\n",
    "        bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "        self._model = AutoModel.from_pretrained(self.model_name,quantization_config=bnb_config,).eval()\n",
    "\n",
    "        if device is None:\n",
    "            if torch.cuda.is_available():\n",
    "                device = \"cuda\"\n",
    "            elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                device = \"mps\"\n",
    "            else:\n",
    "                device = \"cpu\"\n",
    "        self._device = torch.device(device)\n",
    "        self._model.to(self._device)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self._embed_texts(texts)\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self._embed_texts([text])[0]\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def _embed_texts(self, texts: Union[List[str], Iterable[str]]) -> List[List[float]]:\n",
    "        batch_dict = self._tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        batch_dict.to(self._device)\n",
    "        outputs = self._model(**batch_dict)\n",
    "        \n",
    "\n",
    "        embeddings = _last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "        out = embeddings.tolist()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23109fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8992bdaba2204018ac8d66f41d1e2d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "embeddings = MyEmbeddings()\n",
    "\n",
    "DB_PATH = \"./data/embedded/chroma_db\"\n",
    "\n",
    "persist_db = Chroma(\n",
    "    persist_directory=DB_PATH,\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"samsung_quarterly_report\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6bc63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = persist_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057b7249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노을이 붉은 색을 띠는 이유는 주로 빛의 산란과 흡수 현상, 그리고 대기 중의 입자들에 의해 설명됩니다. 이를 좀 더 자세히 살펴보겠습니다.\n",
      "\n",
      "### 1. 빛의 산란\n",
      "- **레이리 산란(Rayleigh Scattering)**: 태양빛은 여러 파장의 빛으로 구성되어 있습니다. 이 빛이 지구 대기를 통과할 때, 대기 중의 분자들과 상호작용합니다.\n",
      "- **파장 의존성**: 레이리 산란은 파장이 짧을수록 더 강하게 일어납니다. 즉, 파란색(약 450nm)과 보라색(약 450nm) 빛이 빨간색(약 700nm) 빛보다 더 많이 산란됩니다.\n",
      "- **낮과 밤의 차이**: 태양은 하늘에서 높이 떠 있을 때, 빛이 대기를 통과하는 거리가 짧습니다. 따라서 파란색 빛이 많이 산란되어 하늘이 파랗게 보입니다.\n",
      "\n",
      "### 2. 노을의 형성\n",
      "- **태양의 위치**: 노을이 지는 시간대는 태양이 지평선 근처에 있을 때입니다. 이때 태양빛은 대기를 더 길게 통과하게 됩니다.\n",
      "- **산란의 누적**: 긴 경로를 통과하면서 파란색 빛은 거의 모두 산란되고, 상대적으로 덜 산란되는 빨간색 빛이 더 많이 남아 도달하게 됩니다.\n",
      "- **대기 입자의 영향**: 노을 시간대에는 대기 중의 먼지, 수증기, 그리고 기타 입자들이 더 많이 존재할 수 있습니다. 이러한 입자들은 빛을 추가적으로 산란시키고, 특히 빨간색 빛을 더 많이 통과시킵니다.\n",
      "\n",
      "### 3. 추가적인 요인\n",
      "- **대기 오염**: 대기 중의 오염 물질이나 수증기는 노을의 색을 더욱 붉게 만들 수 있습니다. 이는 빛이 더 많은 입자와 상호작용하면서 붉은 색이 강화되기 때문입니다.\n",
      "- **지형적 요인**: 산이나 건물 등 지형적 요인도 노을의 색과 강도에 영향을 줄 수 있습니다.\n",
      "\n",
      "### 결론\n",
      "노을이 붉은 색을 띠는 것은 주로 태양빛이 대기를 길게 통과하면서 파란색 빛이 많이 산란되고, 상대적으로 덜 산란된 빨간색 빛이 더 많이 도달하기 때문입니다. 또한, 대기 중의 입자와 기타 환경적 요인들이 이 과정을 더욱 강화시킵니다. 이러한 과학적 원리들이 결합되어 우리가 보는 아름다운 노을의 붉은 색을 만들어냅니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Modify OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"},\n",
    "]\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "question = \"노을이 붉은 색인 이유를 과학적으로 자세히 설명해줘\"\n",
    "\n",
    "answer = llm.invoke(question)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31752ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai/gpt-oss-20b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이혁재 이사는 **2025년 3월 19일** 정기주주총회에서 선임되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    temperature=0.1,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    )\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"이혁재 이사가 언제 선임되었지?\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc8ca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skt/A.X-4.0-Light\n",
      "이혁재 이사가 선임된 날짜는 2025년 3월 19일입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "print(model)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    temperature=0.1,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    )\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"이혁재 이사가 언제 선임되었지?\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b813b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skt/A.X-4.0-Light\n",
      "부문별 재무제표 보고서를 작성하기 위해 제공된 문서를 분석하였습니다. 아래는 삼성전자 2025년 1분기 부문별 재무제표 보고서입니다.\n",
      "\n",
      "### 부문별 재무제표\n",
      "\n",
      "#### 당분기 (단위: 백만원)\n",
      "\n",
      "| 항목 | DX 부문 | DS 부문 | 기업 전체 총계 합계 |\n",
      "|------|---------|---------|---------------------|\n",
      "| 매출액 | 33,023,911 | 24,658,121 | 55,534,871 |\n",
      "| 감가상각비 | 148,483 | 8,234,941 | 8,436,591 |\n",
      "| 무형자산상각비 | 409,194 | 183,926 | 652,336 |\n",
      "| 영업이익 | 1,388,471 | 82,013 | 1,469,273 |\n",
      "\n",
      "\n",
      "#### 부문별 정보 설명\n",
      "- **DX 부문**: 주로 소비자 전자제품 및 IT 기기를 포함하는 부문입니다.\n",
      "- **DS 부문**: 반도체 및 관련 제품을 포함하는 부문입니다.\n",
      "- **기업 전체 총계**: 두 부문의 합으로, 회사의 전체 재무 성과를 나타냅니다.\n",
      "\n",
      "\n",
      "### 추가 정보\n",
      "- **감가상각비**와 **무형자산상각비**는 각 부문별로 계산되어 있으며, 이는 자산의 사용과 관련된 비용을 나타냅니다.\n",
      "- **영업이익**은 각 부문의 수익성을 평가하는 중요한 지표로, 내부거래 조정이 반영된 후의 금액입니다.\n",
      "- 보고부문별 자산과 부채는 경영위원회에 정기적으로 제공되지 않아 본 보고서에 포함되지 않았습니다.\n",
      "\n",
      "\n",
      "### 참고\n",
      "- 이 보고서는 2025년 1분기 기준으로 작성되었습니다.\n",
      "- 부문별 정보는 회사의 전략적 의사결정을 위한 경영위원회 보고용으로 사용되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "print(model)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    temperature=0.1,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    )\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"부문별 재무제표 보고서를 작성해줘\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56274f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**삼성전자 2025년 2분기 부문별 재무제표 보고서**  \n",
      "(단위 : 백만원)\n",
      "\n",
      "| 항목 | DX 부문 (기업 전체 총계) | DS 부문 (기업 전체 총계) | 기업 전체 총계 합계 |\n",
      "|---|---:|---:|---:|\n",
      "| **매출액** | 33,023,911 | 24,658,121 | 55,534,871 |\n",
      "| **감가상각비** | 148,483 | 8,234,941 | 8,436,591 |\n",
      "| **무형자산상각비** | 409,194 | 183,926 | 652,336 |\n",
      "| **영업이익** | 1,388,471 | 82,013 | 1,469,273 |\n",
      "\n",
      "> **주요 포인트**  \n",
      "> 1. **DX 부문**은 2025년 2분기 매출액이 33,023,911백만원으로, 전체 매출의 약 59%를 차지합니다. 감가상각비는 148,483백만원으로 상대적으로 낮으며, 무형자산상각비는 409,194백만원입니다. 영업이익은 1,388,471백만원으로 부문별 가장 높은 수익성을 보였습니다.  \n",
      "> 2. **DS 부문**은 매출액이 24,658,121백만원으로 DX 부문보다 낮지만, 감가상각비가 8,234,941백만원으로 크게 차이가 납니다. 무형자산상각비는 183,926백만원이며, 영업이익은 82,013백만원으로 DX 부문에 비해 낮은 수준입니다.  \n",
      "> 3. **기업 전체**는 매출액 55,534,871백만원, 감가상각비 8,436,591백만원, 무형자산상각비 652,336백만원, 영업이익 1,469,273백만원을 기록했습니다.  \n",
      "> 4. 보고서에 명시된 바와 같이, **기타 부문**은 별도로 표시되지 않았으며, 보고부문별 자산·부채는 경영위원회에 정기적으로 제공되지 않아 포함되지 않았습니다.  \n",
      "\n",
      "> **참고**  \n",
      "> - 부문별 보고는 조직 및 수익을 창출하는 제품의 유형을 기준으로 식별되며, 경영위원회는 부문에 배분될 자원과 성과를 영업이익을 기준으로 평가합니다.  \n",
      "> - 본 표는 2025년 2분기(당분기) 기준이며, 전분기와의 비교는 별도 자료를 참고하시기 바랍니다.  \n",
      "\n",
      "필요하신 추가 분석(예: 전분기 대비 성장률, 부채·자산 비율 등)이 있으면 알려 주세요.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    temperature=0.1,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    )\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"부문별 재무제표 보고서를 작성해줘\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19111b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025년 삼성전자의 매출 실적은 2025년 1분기(제57기) 기준으로 다음과 같습니다.\n",
      "\n",
      "| 부문 | 매출유형 | 주요 품목 | 2025년 1분기 매출(억 원) | 전년 동기 대비 증가율 |\n",
      "|------|----------|-----------|---------------------------|------------------------|\n",
      "| **DX 부문** | 제·상품, 용역 및 기타매출 | TV, 모니터, 냉장고, 세탁기, 에어컨, 스마트폰, 네트워크시스템, PC 등 | 517,172 | +9.4 % |\n",
      "| **DS 부문** | 제·상품, 용역 및 기타매출 | DRAM, NAND Flash, 모바일 AP 등 | 251,310 | +8.6 % |\n",
      "| **SDC 부문** | 제·상품, 용역 및 기타매출 | 스마트폰용 OLED 패널 등 | 58,669 | +8.9 % |\n",
      "| **Harman 부문** | 제·상품, 용역 및 기타매출 | 디지털 콕핏, 카오디오, 포터블 스피커 등 | 34,194 | +6.8 % |\n",
      "| **기타** | 부문간 내부거래 제거 등 |  | △69,940 | – |\n",
      "\n",
      "- **총 매출**: 791,405억 원 (79조 1,405억원)  \n",
      "- **전년 동기 대비**: 10.0 % 증가\n",
      "\n",
      "이 수치는 2025년 5월 15일에 발표된 분기보고서(제57기)에서 확인할 수 있습니다. 2025년 전체 연간 실적은 아직 발표되지 않았으므로, 현재는 1분기 실적만을 기준으로 말씀드릴 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    temperature=0.1,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    )\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"2025년 삼성전자의 매출실적에 대해 알려줘\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e349152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This morning's meeting was highly productive, as we successfully addressed and resolved all world conflicts.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Please respond to the user's request only based on the given context.\"),\n",
    "    (\"user\", \"Question: {question}\\nContext: {context}\")\n",
    "])\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "question = \"Can you summarize this morning's meetings?\"\n",
    "context = \"During this morning's meeting, we solved all world conflict.\"\n",
    "chain.invoke({\"question\": question, \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0b938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung-qreport-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
