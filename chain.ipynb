{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d350fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/how_to/custom_embeddings/\n",
    "\n",
    "from typing import List, Iterable, Union\n",
    "\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel, BitsAndBytesConfig\n",
    "\n",
    "def _last_token_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "class MyEmbeddings(Embeddings):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = \"Qwen/Qwen3-Embedding-8B\",\n",
    "        *,\n",
    "        max_length: int = 8192,\n",
    "        device = None\n",
    "    ):\n",
    "        self.model_name = model\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self._tokenizer = tokenizer = AutoTokenizer.from_pretrained(self.model_name, padding_side='left')\n",
    "\n",
    "        bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "        self._model = AutoModel.from_pretrained(self.model_name,quantization_config=bnb_config,).eval()\n",
    "\n",
    "        if device is None:\n",
    "            if torch.cuda.is_available():\n",
    "                device = \"cuda\"\n",
    "            elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                device = \"mps\"\n",
    "            else:\n",
    "                device = \"cpu\"\n",
    "        self._device = torch.device(device)\n",
    "        self._model.to(self._device)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self._embed_texts(texts)\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self._embed_texts([text])[0]\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def _embed_texts(self, texts: Union[List[str], Iterable[str]]) -> List[List[float]]:\n",
    "        batch_dict = self._tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        batch_dict.to(self._device)\n",
    "        outputs = self._model(**batch_dict)\n",
    "        \n",
    "\n",
    "        embeddings = _last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "        out = embeddings.tolist()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23109fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9028b94750734962b6cb16fa6bf27bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "embeddings = MyEmbeddings()\n",
    "\n",
    "DB_PATH = \"./data/embedded/chroma_db\"\n",
    "\n",
    "persist_db = Chroma(\n",
    "    persist_directory=DB_PATH,\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"samsung_quarterly_report\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6bc63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = persist_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057b7249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Modify OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"},\n",
    "]\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "question = \"노을이 붉은 색인 이유를 과학적으로 자세히 설명해줘\"\n",
    "\n",
    "answer = llm.invoke(question)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31752ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai/gpt-oss-20b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이혁재 이사는 **2025년 3월 19일** 정기주주총회에서 선임되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    temperature=0.1,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    )\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"이혁재 이사가 언제 선임되었지?\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56274f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**삼성전자 2025년 2분기 부문별 재무제표 보고서**  \n",
      "(단위 : 백만원)\n",
      "\n",
      "| 항목 | DX 부문 (기업 전체 총계) | DS 부문 (기업 전체 총계) | 기업 전체 총계 합계 |\n",
      "|---|---:|---:|---:|\n",
      "| **매출액** | 33,023,911 | 24,658,121 | 55,534,871 |\n",
      "| **감가상각비** | 148,483 | 8,234,941 | 8,436,591 |\n",
      "| **무형자산상각비** | 409,194 | 183,926 | 652,336 |\n",
      "| **영업이익** | 1,388,471 | 82,013 | 1,469,273 |\n",
      "\n",
      "> **주요 포인트**  \n",
      "> 1. **DX 부문**은 2025년 2분기 매출액이 33,023,911백만원으로, 전체 매출의 약 59%를 차지합니다. 감가상각비는 148,483백만원으로 상대적으로 낮으며, 무형자산상각비는 409,194백만원입니다. 영업이익은 1,388,471백만원으로 부문별 가장 높은 수익성을 보였습니다.  \n",
      "> 2. **DS 부문**은 매출액이 24,658,121백만원으로 DX 부문보다 낮지만, 감가상각비가 8,234,941백만원으로 크게 차이가 납니다. 무형자산상각비는 183,926백만원이며, 영업이익은 82,013백만원으로 DX 부문에 비해 낮은 수준입니다.  \n",
      "> 3. **기업 전체**는 매출액 55,534,871백만원, 감가상각비 8,436,591백만원, 무형자산상각비 652,336백만원, 영업이익 1,469,273백만원을 기록했습니다.  \n",
      "> 4. 보고서에 명시된 바와 같이, **기타 부문**은 별도로 표시되지 않았으며, 보고부문별 자산·부채는 경영위원회에 정기적으로 제공되지 않아 포함되지 않았습니다.  \n",
      "\n",
      "> **참고**  \n",
      "> - 부문별 보고는 조직 및 수익을 창출하는 제품의 유형을 기준으로 식별되며, 경영위원회는 부문에 배분될 자원과 성과를 영업이익을 기준으로 평가합니다.  \n",
      "> - 본 표는 2025년 2분기(당분기) 기준이며, 전분기와의 비교는 별도 자료를 참고하시기 바랍니다.  \n",
      "\n",
      "필요하신 추가 분석(예: 전분기 대비 성장률, 부채·자산 비율 등)이 있으면 알려 주세요.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    temperature=0.1,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    )\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"부문별 재무제표 보고서를 작성해줘\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19111b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025년 삼성전자의 매출 실적은 2025년 1분기(제57기) 기준으로 다음과 같습니다.\n",
      "\n",
      "| 부문 | 매출유형 | 주요 품목 | 2025년 1분기 매출(억 원) | 전년 동기 대비 증가율 |\n",
      "|------|----------|-----------|---------------------------|------------------------|\n",
      "| **DX 부문** | 제·상품, 용역 및 기타매출 | TV, 모니터, 냉장고, 세탁기, 에어컨, 스마트폰, 네트워크시스템, PC 등 | 517,172 | +9.4 % |\n",
      "| **DS 부문** | 제·상품, 용역 및 기타매출 | DRAM, NAND Flash, 모바일 AP 등 | 251,310 | +8.6 % |\n",
      "| **SDC 부문** | 제·상품, 용역 및 기타매출 | 스마트폰용 OLED 패널 등 | 58,669 | +8.9 % |\n",
      "| **Harman 부문** | 제·상품, 용역 및 기타매출 | 디지털 콕핏, 카오디오, 포터블 스피커 등 | 34,194 | +6.8 % |\n",
      "| **기타** | 부문간 내부거래 제거 등 |  | △69,940 | – |\n",
      "\n",
      "- **총 매출**: 791,405억 원 (79조 1,405억원)  \n",
      "- **전년 동기 대비**: 10.0 % 증가\n",
      "\n",
      "이 수치는 2025년 5월 15일에 발표된 분기보고서(제57기)에서 확인할 수 있습니다. 2025년 전체 연간 실적은 아직 발표되지 않았으므로, 현재는 1분기 실적만을 기준으로 말씀드릴 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from openai import OpenAI\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    temperature=0.1,\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    )\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"2025년 삼성전자의 매출실적에 대해 알려줘\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e349152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This morning's meeting was highly productive, as we successfully addressed and resolved all world conflicts.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Please respond to the user's request only based on the given context.\"),\n",
    "    (\"user\", \"Question: {question}\\nContext: {context}\")\n",
    "])\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "question = \"Can you summarize this morning's meetings?\"\n",
    "context = \"During this morning's meeting, we solved all world conflict.\"\n",
    "chain.invoke({\"question\": question, \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0b938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung-qreport-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
