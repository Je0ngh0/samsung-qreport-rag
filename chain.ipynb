{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d350fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/how_to/custom_embeddings/\n",
    "\n",
    "from typing import List, Iterable, Union\n",
    "\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel, BitsAndBytesConfig\n",
    "\n",
    "def _last_token_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "class MyEmbeddings(Embeddings):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = \"Qwen/Qwen3-Embedding-8B\",\n",
    "        *,\n",
    "        max_length: int = 8192,\n",
    "        device = None\n",
    "    ):\n",
    "        self.model_name = model\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self._tokenizer = tokenizer = AutoTokenizer.from_pretrained(self.model_name, padding_side='left')\n",
    "\n",
    "        bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "        self._model = AutoModel.from_pretrained(self.model_name,quantization_config=bnb_config,).eval()\n",
    "\n",
    "        if device is None:\n",
    "            if torch.cuda.is_available():\n",
    "                device = \"cuda\"\n",
    "            elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                device = \"mps\"\n",
    "            else:\n",
    "                device = \"cpu\"\n",
    "        self._device = torch.device(device)\n",
    "        self._model.to(self._device)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self._embed_texts(texts)\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self._embed_texts([text])[0]\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def _embed_texts(self, texts: Union[List[str], Iterable[str]]) -> List[List[float]]:\n",
    "        batch_dict = self._tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        batch_dict.to(self._device)\n",
    "        outputs = self._model(**batch_dict)\n",
    "        \n",
    "\n",
    "        embeddings = _last_token_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "        out = embeddings.tolist()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23109fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df947ea01dbe4687b9980243b61ae2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "embeddings = MyEmbeddings()\n",
    "\n",
    "DB_PATH = \"./data/embedded/chroma_db\"\n",
    "\n",
    "persist_db = Chroma(\n",
    "    persist_directory=DB_PATH,\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"samsung_quarterly_report\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6bc63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = persist_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31752ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제55기 정기주주총회는 2024년 3월 20일에 개최되었습니다. 주요 안건으로는 제55기 재무상태표, 손익계산서 및 이익잉여금처분계산서 등 재무제표 승인, 사외이사 신재윤 선임, 감사위원회 위원이 되는 사외이사 조혜정 선임, 감사위원회 위원 유명희 선임, 이사 보수한도 승인, 정관 일부 변경 등이 있었습니다. 모든 안건은 가결되었습니다. 주주총회에서는 55기 영업성과 및 배당 관련 설명, 주주가치 제고 방안, 사업경쟁력 관련 질의응답 등이 논의되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"55기 주주총회에 대해 알려줘\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e349152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This morning's meeting was highly productive, as we successfully addressed and resolved all world conflicts.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Please respond to the user's request only based on the given context.\"),\n",
    "    (\"user\", \"Question: {question}\\nContext: {context}\")\n",
    "])\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "question = \"Can you summarize this morning's meetings?\"\n",
    "context = \"During this morning's meeting, we solved all world conflict.\"\n",
    "chain.invoke({\"question\": question, \"context\": context})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung-qreport-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
