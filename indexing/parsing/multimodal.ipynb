{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae2d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, AsyncIterator, List\n",
    "from langchain_core.document_loaders import BaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from pdf2image import convert_from_path\n",
    "from openai import OpenAI\n",
    "import tempfile\n",
    "import base64\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class MultimodalLoader(BaseLoader):\n",
    "    def __init__(self, file_path: str, model: str = \"gpt-5-nano\", first_page: int = None, last_page: int = None) -> None:\n",
    "\n",
    "        self.file_path = file_path\n",
    "        self.model = model\n",
    "        self.first_page = first_page\n",
    "        self.last_page = last_page\n",
    "\n",
    "    def _image_to_text(self, image) -> str:\n",
    "        \"\"\"단일 이미지에서 텍스트 추출 (동기)\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".png\") as tmp:\n",
    "            image.save(tmp.name, format=\"PNG\")\n",
    "            with open(tmp.name, \"rb\") as f:\n",
    "                b64_image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "                response = client.responses.create(\n",
    "                    model=self.model,\n",
    "                    input=[\n",
    "                        {\"role\": \"developer\", \"content\": '''You are a multimodal OCR and document parsing assistant. \n",
    "Your task is to extract text from images of PDF pages and return it in clean, structured Markdown format.\n",
    "\n",
    "### Instructions:\n",
    "1. Read the provided image(s) of the PDF page carefully. \n",
    "2. Extract all visible text, preserving the original reading order.\n",
    "3. Use **Markdown syntax** for structure:\n",
    "   - Use `#`, `##`, `###` for headings (follow the visual hierarchy of the document).\n",
    "   - Use bullet points (`-` or `*`) and numbered lists where appropriate.\n",
    "   - Use code blocks (```) only if the document contains actual code or fixed-width text.\n",
    "   - Use tables in Markdown format if the document contains tabular data.\n",
    "4. Do **not** insert hallucinated content. Only output text that is actually present in the image.\n",
    "5. Correct minor OCR errors if possible, but do not paraphrase or rewrite the content.\n",
    "6. If an image has no readable text, return:  \n",
    "\n",
    "[No readable text found]\n",
    "\n",
    "### Output:\n",
    "Return only the extracted content in Markdown, without additional explanations.'''},\n",
    "                        {\"role\": \"user\", \"content\": [\n",
    "                            {\"type\": \"input_image\", \"image_url\": f\"data:image/png;base64,{b64_image}\"}\n",
    "                        ]}\n",
    "                    ],\n",
    "                )\n",
    "        return response.output_text\n",
    "\n",
    "    def lazy_load(self) -> Iterator[Document]:\n",
    "        \"\"\"동기식 lazy loader\"\"\"\n",
    "        pages = convert_from_path(\n",
    "            self.file_path,\n",
    "            dpi=512,\n",
    "            first_page=self.first_page,\n",
    "            last_page=self.last_page\n",
    "            )\n",
    "        total_pages = len(pages)\n",
    "        for page_num, image in enumerate(pages, start=1):\n",
    "            text = self._image_to_text(image)\n",
    "            yield Document(\n",
    "                page_content=text,\n",
    "                metadata={\"source\": self.file_path, \"page\": page_num, \"total_pages\": total_pages},\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f73245a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = MultimodalLoader(\n",
    "    \"../../data/raw/[삼성전자]분기보고서(2025.05.15).pdf\",\n",
    "    model=\"gpt-5-mini\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "output_file = \"../../data/parsed/multimodal.jsonl\"\n",
    "\n",
    "if not os.path.exists(output_file):\n",
    "    open(output_file, \"w\", encoding=\"utf-8\").close()\n",
    "\n",
    "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "    for doc in loader.lazy_load():\n",
    "        record = doc.model_dump()\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d9fab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "output_file = \"../../data/parsed/multimodal.jsonl\"\n",
    "\n",
    "docs = []\n",
    "with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        d = json.loads(line) \n",
    "        docs.append(Document(**d))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
